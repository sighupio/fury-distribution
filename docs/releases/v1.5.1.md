# Fury Distribution v1.5.1

Welcome to Fury v1.5.1. This distribution version includes a hotfix related to gathering metrics and logs from the
[ingress module](https://github.com/sighupio/fury-kubernetes-ingress).

Please, carefully read the [upgrade procedure](#procedure) before applying it.

## Changelog

The most significant changes are listed below:

- [ingress](https://github.com/sighupio/fury-kubernetes-ingress) ğŸ“¦ core module: v1.9.0 -> [**v1.9.1**](https://github.com/sighupio/fury-kubernetes-ingress/releases/tag/v1.9.1)
  - FIX: [nginx] ingress controller. Re-enable custom logging parser
  - FIX: [cert-manager]. Re-enable exposing metrics.

- All the container images come from the SIGHUP registry to avoid rate limits.

## Upgrade path

### Procedure

Before upgrade delete some objects as they do not allow patch in place,
the procedure shouldn't cause downtime on the application side.

```bash
$ kubectl -n cert-manager delete deployment cert-manager-webhook cert-manager-cainjector cert-manager
deployment.apps "cert-manager-webhook" deleted
deployment.apps "cert-manager-cainjector" deleted
deployment.apps "cert-manager" deleted
```

Then, to upgrade the distribution from `v1.5.0` to `v1.5.1`, download this new version, vendor the dependencies,
finally applying the `kustomize` project.

```bash
furyctl vendor -H
kustomize build . | kubectl apply -f -
```

> **NOTE**: *The upgrade takes some minutes (depends on the cluster size), and you should expect some downtime during
the upgrade process.*

## Test it

If you want to test the distribution in a test environment, spin up a
[`kind`](https://github.com/kubernetes-sigs/kind/releases/tag/v0.9.0) cluster, then deploy all rendered manifests.

```bash
$ kind version
kind v0.9.0 go1.15.2 darwin/amd64
$ curl -Ls https://github.com/sighupio/fury-distribution/releases/download/v1.5.1/kind-config-v1.5.1.yml | kind create cluster --config -
Creating cluster "kind" ...
 âœ“ Ensuring node image (kindest/node:v1.19.1) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦ ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing StorageClass ğŸ’¾
 âœ“ Joining worker nodes ğŸšœ
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community ğŸ™‚
$ kubectl apply -f https://github.com/sighupio/fury-distribution/releases/download/v1.5.1/fury-distribution-v1.5.1.yml
namespace/cert-manager created
namespace/gatekeeper-system created
namespace/ingress-nginx created
namespace/logging created
namespace/monitoring created
customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
<TRUNCATED OUTPUT>
```

> **NOTE**: *Run `kubectl apply` multiple times until you see no errors in the console*

[fluentd]: https://github.com/fluent/fluentd/releases/tag/v1.11.5
[curator]: https://github.com/elastic/curator/releases/tag/v5.8.3
[kibana]: https://github.com/elastic/kibana/releases/tag/v7.10.1
[elasticsearch]: https://github.com/elastic/elasticsearch/releases/tag/v7.10.1
[Cerebro]: https://github.com/lmenezes/cerebro/releases/tag/v0.9.3
[Velero]: https://velero.io/
[cert-manager]: https://github.com/jetstack/cert-manager
[forecastle]: https://github.com/stakater/Forecastle
[nginx]: https://github.com/kubernetes/ingress-nginx
[metrics-server]: https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-server
[node-exporter]: https://github.com/prometheus/node_exporter
[kube-state-metrics]: https://github.com/kubernetes/kube-state-metrics
[Grafana]: https://grafana.com/
[Alertmanager]: https://github.com/prometheus/alertmanager
[Prometheus]: https://prometheus.io/
[Prometheus Operator]: https://github.com/prometheus-operator/prometheus-operator
[Calico]: https://www.projectcalico.org/
[Gatekeeper]: https://github.com/open-policy-agent/gatekeeper
[Gatekeeper Policy Manager]: https://github.com/sighupio/gatekeeper-policy-manager
